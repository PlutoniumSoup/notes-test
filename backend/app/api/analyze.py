from fastapi import APIRouter, HTTPException, Query, Depends
from typing import List
from ..services.llm import analyze_note_with_llm
from ..core.security import get_current_user
from ..db.models import User
from ..services.wikipedia import populate_knowledge_base_from_keywords
from ..services.hierarchy import create_hierarchical_graph
from ..db.neo4j import get_neo4j_driver
from ..db.elastic import get_es
from ..core.config import get_settings
from ..models.schemas import GraphNode, GraphLink, GraphData
from ..services.knowledge import upsert_node, link_nodes, search_nodes_by_keywords, graph_from_cypher_records
from ..services.node_matching import normalize_for_id, find_matching_node, merge_node_data
from ..services.prompt_injection_filter import sanitize_content, detect_injection_attempt
import hashlib
import logging

logger = logging.getLogger(__name__)


router = APIRouter(prefix="/analyze", tags=["analyze"])


@router.post("/note")
async def analyze_note(
    content: str = Query(..., min_length=10),
    note_id: str = Query(None),  # Optional note ID for tracking
    current_user: User = Depends(get_current_user)
):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–º–µ—Ç–∫—É —Å –ø–æ–º–æ—â—å—é LLM –∏ —Å–æ–∑–¥–∞–µ—Ç/—Å–≤—è–∑—ã–≤–∞–µ—Ç —É–∑–ª—ã –≥—Ä–∞—Ñ–∞ –∑–Ω–∞–Ω–∏–π
    """
    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    if len(content) > 2000:
        raise HTTPException(
            status_code=400,
            detail="–°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è –∑–∞–º–µ—Ç–∫–∞! –ú–∞–∫—Å–∏–º—É–º 2000 —Å–∏–º–≤–æ–ª–æ–≤. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞–∑–±–µ–π—Ç–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–º–µ—Ç–æ–∫."
        )
    
    # –ó–∞—â–∏—Ç–∞ –æ—Ç prompt injection
    is_injection, patterns = detect_injection_attempt(content)
    if is_injection:
        logger.warning(f"Prompt injection attempt detected for user {current_user.id}. Patterns: {patterns}")
        # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –æ—Ç –æ–ø–∞—Å–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
        content = sanitize_content(content)
        if len(content.strip()) < 10:
            raise HTTPException(
                status_code=400,
                detail="Content contains prohibited instructions and cannot be processed"
            )

    # –ê–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é LLM
    analysis = analyze_note_with_llm(content)
    if not analysis:
        return {
            "tags": [],
            "nodes": [],
            "links": [],
            "model_used": "none",
            "main_topic": "–ê–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è"
        }

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ù–û–í–û–ì–û —Ñ–æ—Ä–º–∞—Ç–∞ (concepts/relationships)
    concepts = analysis.get("concepts", [])
    relationships = analysis.get("relationships", [])
    tags = analysis.get("tags", [])
    main_topic = analysis.get("main_topic", "")
    model_used = analysis.get("model_used", "unknown")
    
    logger.info(f"Analysis completed. Model: {model_used}, Topic: {main_topic}, Concepts: {len(concepts)}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ —É–∑–ª–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –¥–Ω—è
    driver = get_neo4j_driver()
    try:
        with driver.session() as session:
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö —É–∑–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã
            new_nodes_count = len(concepts)
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∑–ª–æ–≤, —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –¥–Ω—è
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å - —Å—á–∏—Ç–∞–µ–º —É–∑–ª—ã —Å created_at –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –¥–Ω—è
            nodes_created_result = session.run(
                """
                MATCH (n:Node {user_id: $user_id})
                WHERE n.created_at IS NOT NULL
                AND n.created_at >= datetime() - duration({days: 2})
                RETURN count(n) AS node_count
                """,
                user_id=str(current_user.id)
            )
            record = nodes_created_result.single()
            nodes_created_last_2_days = record["node_count"] if record else 0
            
            # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª (—Å—Ç–∞—Ä—ã–µ —É–∑–ª—ã –±–µ–∑ created_at), —Å—á–∏—Ç–∞–µ–º –≤—Å–µ —É–∑–ª—ã
            # –Ω–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏—Ö –±–æ–ª—å—à–µ 30 (—Ç–æ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è–µ–º –ª–∏–º–∏—Ç)
            if nodes_created_last_2_days == 0:
                total_nodes_result = session.run(
                    """
                    MATCH (n:Node {user_id: $user_id})
                    RETURN count(n) AS total_count
                    """,
                    user_id=str(current_user.id)
                )
                total_record = total_nodes_result.single()
                total_nodes = total_record["total_count"] if total_record else 0
                
                # –ï—Å–ª–∏ —É–∑–ª–æ–≤ –±–æ–ª—å—à–µ 30, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –ª–∏–º–∏—Ç –¥–æ—Å—Ç–∏–≥–Ω—É—Ç (—Å—Ç–∞—Ä—ã–µ —É–∑–ª—ã)
                if total_nodes >= 100:
                    nodes_created_last_2_days = 100
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç
            MAX_NODES_PER_2_DAYS = 100
            if nodes_created_last_2_days + new_nodes_count > MAX_NODES_PER_2_DAYS:
                remaining = MAX_NODES_PER_2_DAYS - nodes_created_last_2_days
                if remaining <= 0:
                    raise HTTPException(
                        status_code=429,
                        detail="üö´ –õ–∏–º–∏—Ç —É–∑–ª–æ–≤ –∏—Å—á–µ—Ä–ø–∞–Ω! –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –¥–Ω—è —Å–æ–∑–¥–∞–Ω–æ —É–∂–µ 100 —É–∑–ª–æ–≤. "
                               "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –±–µ—Ä–µ–≥–∏—Ç–µ —Ç–æ–∫–µ–Ω—ã –∞–≤—Ç–æ—Ä–∞ - –ø—Ä–æ–µ–∫—Ç –º–æ–∂–µ—Ç —Ä–∞–∑–≤–∞–ª–∏—Ç—å—Å—è –Ω–∞ —ç—Ç–∞–ø–µ –±—É—Ç—Å—Ç—Ä—ç–ø–ø–∏–Ω–≥–∞"
                               "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –ø–∞—Ä—É –¥–Ω–µ–π –∏–ª–∏ —É–¥–∞–ª–∏—Ç–µ —Å—Ç–∞—Ä—ã–µ —É–∑–ª—ã."
                    )
                else:
                    raise HTTPException(
                        status_code=429,
                        detail=f"‚ö†Ô∏è –ü–æ—á—Ç–∏ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç! –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –¥–Ω—è —Å–æ–∑–¥–∞–Ω–æ {nodes_created_last_2_days} —É–∑–ª–æ–≤. "
                               f"–ú–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –µ—â–µ —Ç–æ–ª—å–∫–æ {remaining} —É–∑–ª(–æ–≤). "
                               "–ë–µ—Ä–µ–≥–∏—Ç–µ —Ç–æ–∫–µ–Ω—ã –∞–≤—Ç–æ—Ä–∞ - –ø—Ä–æ–µ–∫—Ç –º–æ–∂–µ—Ç —Ä–∞–∑–≤–∞–ª–∏—Ç—å—Å—è –Ω–∞ —ç—Ç–∞–ø–µ –±—É—Ç—Å—Ç—Ä—ç–ø–ø–∏–Ω–≥–∞!"
                    )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error checking node limit: {e}")
        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–∏–º–∏—Ç
    
    # –°–æ–∑–¥–∞–µ–º —É–∑–ª—ã –∏–∑ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤
    created_nodes = []
    node_id_map = {}  # map concept_id -> node_id
    
    try:
        with driver.session() as session:
            # –°–Ω–∞—á–∞–ª–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–ª–∞–≤–Ω—ã–π –∫–æ–Ω—Ü–µ–ø—Ç (—Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–≤—è–∑–µ–π)
            concept_connections = {}
            for rel in relationships:
                source = rel.get("source", "")
                target = rel.get("target", "")
                concept_connections[source] = concept_connections.get(source, 0) + 1
                concept_connections[target] = concept_connections.get(target, 0) + 1
            
            # –ì–ª–∞–≤–Ω—ã–π –∫–æ–Ω—Ü–µ–ø—Ç - —Ç–æ—Ç, —É –∫–æ—Ç–æ—Ä–æ–≥–æ –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ —Å–≤—è–∑–µ–π
            main_concept_id = max(concept_connections.items(), key=lambda x: x[1])[0] if concept_connections else (concepts[0].get("id", "") if concepts else "")
            
            # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ —Å–≤—è–∑–µ–π –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É—Ä–æ–≤–Ω–µ–π
            adjacency = {}
            for rel in relationships:
                source = rel.get("source", "")
                target = rel.get("target", "")
                if source not in adjacency:
                    adjacency[source] = []
                if target not in adjacency:
                    adjacency[target] = []
                adjacency[source].append(target)
                adjacency[target].append(source)
            
            # BFS –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É—Ä–æ–≤–Ω–µ–π –æ—Ç –≥–ª–∞–≤–Ω–æ–≥–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞
            node_levels = {}
            if main_concept_id and main_concept_id in adjacency:
                queue = [(main_concept_id, 0)]
                visited = {main_concept_id}
                while queue:
                    current, level = queue.pop(0)
                    node_levels[current] = level
                    for neighbor in adjacency.get(current, []):
                        if neighbor not in visited:
                            visited.add(neighbor)
                            queue.append((neighbor, level + 1))
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —É–∑–ª—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
            existing_nodes_result = session.run(
                """
                MATCH (n:Node {user_id: $user_id})
                RETURN n.id AS id, n.label AS label, n.summary AS summary,
                       n.knowledge_gaps AS knowledge_gaps, n.recommendations AS recommendations,
                       n.tags AS tags, n.has_gap AS has_gap, n.level AS level
                """,
                user_id=str(current_user.id)
            )
            existing_nodes = [dict(record) for record in existing_nodes_result]
            logger.info(f"Found {len(existing_nodes)} existing nodes for matching")
            
            # –°–æ–∑–¥–∞–µ–º/–æ–±–Ω–æ–≤–ª—è–µ–º —É–∑–ª—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞
            for concept in concepts:
                concept_id = concept.get("id", "")
                label = concept.get("label", "")
                description = concept.get("description", "")
                knowledge_gaps = concept.get("knowledge_gaps", [])
                recommendations = concept.get("recommendations", [])
                concept_tags = tags  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–µ —Ç–µ–≥–∏ –∑–∞–º–µ—Ç–∫–∏
                
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º label –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ ID
                normalized_label = normalize_for_id(label)
                stable_id = hashlib.md5(f"{normalized_label}_{current_user.id}".encode()).hexdigest()[:16]
                
                logger.debug(f"Processing concept: '{label}' -> normalized: '{normalized_label}' -> stable_id: {stable_id}")
                
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø–æ—Ö–æ–∂–∏–π —É–∑–µ–ª (–ø–æ—Ä–æ–≥ 0.9 –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ª–æ–∂–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π)
                matching_node = find_matching_node(label, existing_nodes, threshold=0.9)
                if not matching_node:
                    # –ü—Ä–æ–±—É–µ–º —Ç–∞–∫–∂–µ –Ω–∞–π—Ç–∏ –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É ID
                    for existing_node in existing_nodes:
                        existing_id = existing_node.get("id", "")
                        if existing_id == stable_id:
                            logger.info(f"Found exact ID match: '{label}' -> node_id={stable_id}")
                            matching_node = (stable_id, 1.0)
                            break
                existing_node_data = None
                merged_data = None
                if matching_node:
                    matched_id, similarity = matching_node
                    logger.info(f"Matching existing node: '{label}' -> node_id={matched_id} (similarity={similarity:.2f})")
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º ID —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —É–∑–ª–∞
                    stable_id = matched_id
                    
                    # –ù–∞—Ö–æ–¥–∏–º –¥–∞–Ω–Ω—ã–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —É–∑–ª–∞
                    existing_node_data = next((n for n in existing_nodes if n.get("id") == matched_id), None)
                    if existing_node_data:
                        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
                        merged_data = merge_node_data(existing_node_data, {
                            "summary": description,
                            "knowledge_gaps": knowledge_gaps,
                            "recommendations": recommendations,
                            "tags": concept_tags
                        })
                        description = merged_data.get("summary", description)
                        knowledge_gaps = merged_data.get("knowledge_gaps", knowledge_gaps)
                        recommendations = merged_data.get("recommendations", recommendations)
                        concept_tags = merged_data.get("tags", concept_tags)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —É–∑–ª–∞
                level = node_levels.get(concept_id, 0)
                if concept_id == main_concept_id:
                    level = 0  # –ì–ª–∞–≤–Ω—ã–π –∫–æ–Ω—Ü–µ–ø—Ç –≤—Å–µ–≥–¥–∞ —É—Ä–æ–≤–µ–Ω—å 0
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                if matching_node and existing_node_data and 'merged_data' in locals() and merged_data:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ merged_data
                    merged_gaps = merged_data.get("knowledge_gaps", knowledge_gaps)
                    merged_recs = merged_data.get("recommendations", recommendations)
                else:
                    # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏–∑ –ë–î
                    existing_node = session.run(
                        """
                        MATCH (n:Node {id: $id, user_id: $user_id})
                        RETURN n.knowledge_gaps AS gaps, n.recommendations AS recs
                        """,
                        id=stable_id,
                        user_id=str(current_user.id)
                    ).single()
                    
                    existing_gaps = existing_node["gaps"] if existing_node and existing_node["gaps"] else []
                    existing_recs = existing_node["recs"] if existing_node and existing_node["recs"] else []
                    
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (—É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã)
                    merged_gaps = list(set(existing_gaps + knowledge_gaps))
                    merged_recs = list(set(existing_recs + recommendations))
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø—Ä–æ–±–µ–ª—ã –∑–Ω–∞–Ω–∏–π
                has_gap = len(merged_gaps) > 0 or len(merged_recs) > 0
                
                # Upsert —É–∑–µ–ª –≤ Neo4j
                result = session.run(
                    """
                    MERGE (n:Node {id: $id, user_id: $user_id})
                    ON CREATE SET 
                        n.label = $label,
                        n.summary = $description,
                        n.tags = $tags,
                        n.created_at = datetime(),
                        n.has_gap = $has_gap,
                        n.level = $level,
                        n.knowledge_gaps = $gaps,
                        n.recommendations = $recs
                    ON MATCH SET
                        n.summary = CASE WHEN n.summary IS NULL OR n.summary = '' THEN $description ELSE n.summary END,
                        n.updated_at = datetime(),
                        n.has_gap = CASE WHEN size($gaps) > 0 OR size($recs) > 0 THEN true ELSE n.has_gap END,
                        n.knowledge_gaps = $gaps,
                        n.recommendations = $recs,
                        n.level = CASE WHEN $level < n.level OR n.level IS NULL THEN $level ELSE n.level END
                    WITH n
                    OPTIONAL MATCH (note:Note {id: $note_id}) 
                    WHERE $note_id IS NOT NULL
                    FOREACH(_ IN CASE WHEN note IS NOT NULL THEN [1] ELSE [] END |
                        MERGE (n)-[:MENTIONED_IN]->(note)
                    )
                    RETURN n
                    """,
                    id=stable_id,
                    user_id=str(current_user.id),
                    label=label,
                    description=description,
                    tags=concept_tags,
                    note_id=note_id,
                    has_gap=has_gap,
                    level=level,
                    gaps=merged_gaps,
                    recs=merged_recs
                )
                
                node_id_map[concept_id] = stable_id
                created_nodes.append({
                    "id": stable_id,
                    "label": label,
                    "summary": description,
                    "has_gap": has_gap,
                    "level": level,
                    "tags": concept_tags,
                    "knowledge_gaps": merged_gaps,
                    "recommendations": merged_recs
                })
            
            # –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑–∏ –º–µ–∂–¥—É —É–∑–ª–∞–º–∏
            links = []
            for rel in relationships:
                source_concept_id = rel.get("source", "")
                target_concept_id = rel.get("target", "")
                rel_type = rel.get("type", "related_to")
                rel_desc = rel.get("description", "")
                
                source_id = node_id_map.get(source_concept_id)
                target_id = node_id_map.get(target_concept_id)
                
                if source_id and target_id:
                    session.run(
                        """
                        MATCH (a:Node {id: $source_id, user_id: $user_id})
                        MATCH (b:Node {id: $target_id, user_id: $user_id})
                        MERGE (a)-[r:RELATED {type: $rel_type}]->(b)
                        ON CREATE SET r.description = $description
                        """,
                        source_id=source_id,
                        target_id=target_id,
                        user_id=str(current_user.id),
                        rel_type=rel_type,
                        description=rel_desc
                    )
                    links.append({
                        "source": source_id,
                        "target": target_id,
                        "relation": rel_type
                    })
            
            # –≠–≤–æ–ª—é—Ü–∏—è —É–∑–ª–æ–≤: –µ—Å–ª–∏ —É —É–∑–ª–∞ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è –±–æ–ª—å—à–∞—è –ø–æ–¥–≤–µ—Ç–∫–∞, –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –µ–≥–æ –≤ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π
            for node_id in node_id_map.values():
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤—è–∑–µ–π (–∏—Å—Ö–æ–¥—è—â–∏—Ö –∏ –≤—Ö–æ–¥—è—â–∏—Ö)
                result = session.run(
                    """
                    MATCH (n:Node {id: $node_id, user_id: $user_id})-[r:RELATED]-(connected:Node {user_id: $user_id})
                    WITH n, count(r) AS connection_count
                    MATCH (n)-[out:RELATED]->(outgoing:Node {user_id: $user_id})
                    WITH n, connection_count, count(out) AS outgoing_count
                    RETURN n.level AS level, connection_count, outgoing_count
                    """,
                    node_id=node_id,
                    user_id=str(current_user.id)
                )
                record = result.single()
                if record:
                    connection_count = record["connection_count"] or 0
                    outgoing_count = record["outgoing_count"] or 0
                    current_level = record["level"] or 0
                    
                    # –ï—Å–ª–∏ —É —É–∑–ª–∞ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è –±–æ–ª—å—à–µ 5 —Å–≤—è–∑–µ–π –∏–ª–∏ –±–æ–ª—å—à–µ 3 –∏—Å—Ö–æ–¥—è—â–∏—Ö, –¥–µ–ª–∞–µ–º –µ–≥–æ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–º
                    if current_level == 1 and (connection_count >= 5 or outgoing_count >= 3):
                        session.run(
                            """
                            MATCH (n:Node {id: $node_id, user_id: $user_id})
                            SET n.level = 0
                            """,
                            node_id=node_id,
                            user_id=str(current_user.id)
                        )
                        logger.info(f"Node {node_id} evolved to level 0 (central) due to {connection_count} connections")
            
        logger.info(f"Created {len(created_nodes)} nodes and {len(links)} links")
        
    except Exception as e:
        logger.error(f"Failed to create graph: {e}")
        logger.exception(e)
        created_nodes = []
        links = []

    return {
        "main_topic": main_topic,
        "tags": tags if tags else ["–æ–±—â–µ–µ"],
        "nodes": created_nodes,
        "links": links,
        "model_used": model_used
    }


@router.get("/graph/{node_id}", response_model=GraphData)
def get_node_graph(
    node_id: str,
    current_user: User = Depends(get_current_user)
):
    """–ü–æ–ª—É—á–∞–µ—Ç –≥—Ä–∞—Ñ –≤–æ–∫—Ä—É–≥ —É–∑–ª–∞"""
    driver = get_neo4j_driver()
    with driver.session() as session:
        records = session.run(
            """
            MATCH (a:Node {id: $id, user_id: $user_id})-[r:RELATED|contains|related_to]-(b:Node {user_id: $user_id})
            RETURN a, r, b
            LIMIT 50
            """,
            id=node_id,
            user_id=str(current_user.id)
        )
        data = graph_from_cypher_records(records)
    return data


@router.get("/node/{node_id}/notes")
def get_node_notes(
    node_id: str,
    current_user: User = Depends(get_current_user)
):
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∑–∞–º–µ—Ç–æ–∫, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è —É–∑–µ–ª"""
    driver = get_neo4j_driver()
    with driver.session() as session:
        result = session.run(
            """
            MATCH (n:Node {id: $node_id, user_id: $user_id})-[:MENTIONED_IN]->(note:Note)
            RETURN note.id AS id, note.title AS title, note.created_at AS created_at
            ORDER BY note.created_at DESC
            """,
            node_id=node_id,
            user_id=str(current_user.id)
        )
        notes = [{"id": r["id"], "title": r["title"], "created_at": str(r["created_at"])} for r in result]
    return {"notes": notes}


@router.patch("/node/{node_id}")
def update_node(
    node_id: str,
    label: str = None,
    summary: str = None,
    current_user: User = Depends(get_current_user)
):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —É–∑–µ–ª –≥—Ä–∞—Ñ–∞"""
    driver = get_neo4j_driver()
    updates = []
    params = {"node_id": node_id, "user_id": str(current_user.id)}
    
    if label is not None:
        updates.append("n.label = $label")
        params["label"] = label
    if summary is not None:
        updates.append("n.summary = $summary")
        params["summary"] = summary
    
    if not updates:
        raise HTTPException(status_code=400, detail="No fields to update")
    
    with driver.session() as session:
        result = session.run(
            f"""
            MATCH (n:Node {{id: $node_id, user_id: $user_id}})
            SET {', '.join(updates)}, n.updated_at = datetime()
            RETURN n
            """,
            **params
        )
        if not result.single():
            raise HTTPException(status_code=404, detail="Node not found")
    
    return {"status": "updated", "node_id": node_id}


@router.delete("/node/{node_id}")
def delete_node(
    node_id: str,
    current_user: User = Depends(get_current_user)
):
    """–£–¥–∞–ª—è–µ—Ç —É–∑–µ–ª –≥—Ä–∞—Ñ–∞ –∏ –≤—Å–µ –µ–≥–æ —Å–≤—è–∑–∏"""
    driver = get_neo4j_driver()
    with driver.session() as session:
        result = session.run(
            """
            MATCH (n:Node {id: $node_id, user_id: $user_id})
            DETACH DELETE n
            RETURN count(n) AS deleted
            """,
            node_id=node_id,
            user_id=str(current_user.id)
        )
        record = result.single()
        if not record or record["deleted"] == 0:
            raise HTTPException(status_code=404, detail="Node not found")
    
    return {"status": "deleted", "node_id": node_id}
